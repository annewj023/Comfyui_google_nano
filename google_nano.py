import os
import io
import base64
import string
import traceback
import uuid
import time
import threading
from datetime import datetime
from typing import List, Tuple, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed

import numpy as np
import torch
from PIL import Image

# å¯¼å…¥æ–°çš„ç®¡ç†å™¨å’Œå·¥å…·ç±»
from .managers import ConfigManager, ApiKeyManager, TaskLogger
from .managers.task_logger import TaskStatus
from .utils import (
    pil_to_base64_data_url, decode_image_from_openrouter_response,
    tensor_to_pils, pils_to_tensor, validate_and_convert_images,
    create_size_mismatch_message, get_actual_display_count, save_images_to_output,
    retry_with_backoff, ApiCallError
)

# å¯é€‰ï¼šæ‰¹é‡æ¨¡å¼æ”¯æŒ XLSX éœ€è¦ pandas å’Œ openpyxl
try:
    import pandas as pd
    HAS_PANDAS = True
except Exception:
    HAS_PANDAS = False

try:
    from openai import OpenAI
except Exception as e:
    OpenAI = None  # å»¶è¿ŸæŠ¥é”™ï¼Œåœ¨è°ƒç”¨æ—¶æç¤ºå®‰è£…ä¾èµ–


# ç§»é™¤æ—§çš„å·¥å…·å‡½æ•°ï¼Œå®ƒä»¬å·²ç»è¿ç§»åˆ°utilsæ¨¡å—


# 1. ä¿®æ”¹ç±»åï¼Œç¡®ä¿å®ƒåœ¨Pythonä¸­æ˜¯å”¯ä¸€çš„
class GoogleNanoNode:
    """
    ä½¿ç”¨ OpenRouter Chat Completionsï¼Œé€šè¿‡å•æ¡ prompt æˆ– CSV/Excel æ‰¹é‡ï¼Œæ ¹æ®è¾“å…¥å‚è€ƒå›¾ç”Ÿæˆæ–°å›¾ã€‚
    
    æ–°åŠŸèƒ½ï¼š
    - å¹¶å‘å›¾ç‰‡ç”Ÿæˆæ•°é‡æ§åˆ¶ï¼ˆ1-10èŒƒå›´ï¼‰
    - å¤šAPI Keyç®¡ç†ä¸è°ƒåº¦ï¼ˆè½®æ¢æ¨¡å¼å’Œå¹¶è¡Œæ¨¡å¼ï¼‰
    - API KeyçŠ¶æ€ç›‘æ§ä¸è‡ªåŠ¨æ’é™¤
    - æ¨¡å‹é€‰æ‹©åŠŸèƒ½
    - é…ç½®æ–‡ä»¶æ¶æ„è°ƒæ•´ï¼ˆconfig.jsonï¼‰
    - å¤±è´¥é‡è¯•æœºåˆ¶å’Œè¯¦ç»†æ—¥å¿—è®°å½•
    
    è¾“å‡ºï¼š
      IMAGE: ç”Ÿæˆçš„å›¾åƒï¼ˆå•å¼ æˆ–æ‰¹é‡æ‹¼æˆ batchï¼‰
      STRING: çŠ¶æ€/æ—¥å¿—
    """

    CATEGORY = "OpenRouter"
    FUNCTION = "generate"
    RETURN_TYPES = ("IMAGE", "STRING", "STRING")  # æ·»åŠ ç¬¬ä¸‰ä¸ªè¿”å›å€¼ç”¨äºKeyçŠ¶æ€æ˜¾ç¤º
    RETURN_NAMES = ("image", "status", "key_status")  # ä¸ºè¾“å‡ºå‘½å
    OUTPUT_NODE = False
    
    # ç±»çº§åˆ«çš„ç®¡ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
    _config_manager = None
    _api_key_manager = None
    _task_logger = None
    _manager_lock = threading.Lock()

    @classmethod
    def _get_managers(cls):
        """è·å–ç®¡ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
        if cls._config_manager is None:
            with cls._manager_lock:
                if cls._config_manager is None:
                    try:
                        print("[DEBUG] åˆå§‹åŒ–ConfigManager...")
                        cls._config_manager = ConfigManager()
                        print("[DEBUG] ConfigManageråˆå§‹åŒ–æˆåŠŸ")
                        
                        print("[DEBUG] åˆå§‹åŒ–ApiKeyManager...")
                        cls._api_key_manager = ApiKeyManager(cls._config_manager)
                        print("[DEBUG] ApiKeyManageråˆå§‹åŒ–æˆåŠŸ")
                        
                        print("[DEBUG] åˆå§‹åŒ–TaskLogger...")
                        log_level = cls._config_manager.get_setting("log_level", "INFO")
                        cls._task_logger = TaskLogger(log_level=log_level)
                        print("[DEBUG] TaskLoggeråˆå§‹åŒ–æˆåŠŸ")
                        
                    except Exception as e:
                        print(f"[ERROR] ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                        import traceback
                        traceback.print_exc()
                        # è¿”å›Noneè®©è°ƒç”¨è€…å¤„ç†
                        return None, None, None
                        
        # éªŒè¯æ‰€æœ‰ç®¡ç†å™¨éƒ½æ­£ç¡®åˆå§‹åŒ–
        if not all([cls._config_manager, cls._api_key_manager, cls._task_logger]):
            print(f"[ERROR] ç®¡ç†å™¨åˆå§‹åŒ–ä¸å®Œæ•´: config={cls._config_manager}, api={cls._api_key_manager}, logger={cls._task_logger}")
            return None, None, None
            
        return cls._config_manager, cls._api_key_manager, cls._task_logger

    @classmethod
    def INPUT_TYPES(cls):
        # è·å–é…ç½®ç®¡ç†å™¨ä»¥è¯»å–æ¨¡å‹åˆ—è¡¨å’ŒAPI KeyçŠ¶æ€
        try:
            config_manager, api_key_manager, _ = cls._get_managers()
            available_models = config_manager.get_models()
            api_keys_status = api_key_manager.get_key_statistics()

            # è°ƒåº¦æ¨¡å¼é€‰é¡¹
            scheduling_modes = ["round_robin", "random", "weighted"]

            # è·å–å·²é…ç½®çš„API Keysä¿¡æ¯ç”¨äºæ˜¾ç¤º
            configured_keys = config_manager.get_api_keys()
            key_count = len(configured_keys)

            # è·å–é…ç½®ä¸­çš„key_management_modeé»˜è®¤å€¼
            default_key_management_mode = config_manager.get_setting("key_management_mode", "åŒæ—¶ä½¿ç”¨ä¸¤è€…")

        except Exception as e:
            # å¦‚æœé…ç½®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
            available_models = [
                "google/gemini-2.5-flash-image-preview:free",
                "google/gemini-2.5-flash-image-preview"
            ]
            scheduling_modes = ["round_robin"]
            key_count = 0
            api_keys_status = {"total_keys": 0, "available_keys": 0, "key_details": []}
            default_key_management_mode = "åŒæ—¶ä½¿ç”¨ä¸¤è€…"
        
        # åˆ›å»ºåŠ¨æ€çš„API Keyè¾“å…¥å­—æ®µ
        api_key_inputs = {}
        
        # ä¸»API Keyï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
        api_key_inputs["api_key_main"] = ("STRING", {
            "multiline": False, 
            "default": "",
            "tooltip": "ä¸»API Keyï¼ˆå¿…å¡«ï¼‰"
        })
        
        # åŠ¨æ€æ·»åŠ é¢å¤–çš„API Keyå­—æ®µï¼ˆæœ€å¤šæ”¯æŒ10ä¸ªï¼‰
        max_keys = min(10, max(1, key_count + 2))  # è‡³å°‘1ä¸ªï¼Œæœ€å¤š10ä¸ªï¼Œå½“å‰æ•°é‡+2ä¸ªå¤‡ç”¨
        
        for i in range(2, max_keys + 1):
            api_key_inputs[f"api_key_{i}"] = ("STRING", {
                "multiline": False, 
                "default": "",
                "tooltip": f"API Key {i}ï¼ˆå¯é€‰ï¼‰"
            })
        
        # API KeyçŠ¶æ€æ˜¾ç¤ºå­—æ®µï¼ˆåªè¯»ä¿¡æ¯ï¼‰
        status_info = []
        if api_keys_status["key_details"]:
            for i, key_detail in enumerate(api_keys_status["key_details"][:5]):  # æœ€å¤šæ˜¾ç¤º5ä¸ªKeyçŠ¶æ€
                try:
                    # å®‰å…¨è·å–å­—æ®µå€¼ï¼Œé¿å…KeyError
                    status = key_detail.get('status', 'æœªçŸ¥')
                    remaining = key_detail.get('remaining', 'æœªçŸ¥')
                    success_rate = key_detail.get('success_rate', 0)
                    status_text = f"Key{i+1}: {status} - å‰©ä½™:{remaining} - æˆåŠŸç‡:{success_rate}%"
                    status_info.append(status_text)
                except Exception as e:
                    status_info.append(f"Key{i+1}: çŠ¶æ€è§£æå¤±è´¥ - {e}")
        
        if not status_info:
            status_info = ["æš‚æ— API KeyçŠ¶æ€ä¿¡æ¯"]
        
        input_types = {
            "required": {
                # ä¸» API Keyï¼ˆå¿…å¡«ï¼‰
                "api_key_main": api_key_inputs["api_key_main"],
                # å›¾åƒè¾“å…¥ï¼ˆè‡³å°‘éœ€è¦ä¸€å¼ ï¼‰
                "image1": ("IMAGE",),
            },
            "optional": {
                # é¢å¤–çš„API Keyè¾“å…¥
                **{k: v for k, v in api_key_inputs.items() if k != "api_key_main"},
                
                # åŸºç¡€å‚æ•°
                "prompt": ("STRING", {
                    "multiline": True, 
                    "default": "",
                    "tooltip": "å•å›¾ç”Ÿæˆçš„æç¤ºè¯"
                }),
                "file_path": ("STRING", {
                    "multiline": False, 
                    "default": "",
                    "tooltip": "æ‰¹é‡å¤„ç†çš„CSV/Excelæ–‡ä»¶è·¯å¾„"
                }),
                "site_url": ("STRING", {
                    "multiline": False, 
                    "default": "",
                    "tooltip": "ç½‘ç«™URLï¼ˆå¯é€‰ï¼‰"
                }),
                "site_name": ("STRING", {
                    "multiline": False, 
                    "default": "",
                    "tooltip": "ç½‘ç«™åç§°ï¼ˆå¯é€‰ï¼‰"
                }),
                
                # æ¨¡å‹é€‰æ‹©
                "model": (available_models, {
                    "default": available_models[0] if available_models else "google/gemini-2.5-flash-image-preview:free",
                    "tooltip": "é€‰æ‹©è¦ä½¿ç”¨çš„AIæ¨¡å‹"
                }),
                
                # å¹¶å‘æ§åˆ¶
                "max_concurrent": ("INT", {
                    "default": 3, 
                    "min": 1, 
                    "max": 10, 
                    "step": 1,
                    "tooltip": "æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°é‡ï¼ˆ1-10ï¼‰"
                }),
                
                # è°ƒåº¦ç­–ç•¥
                "scheduling_mode": (scheduling_modes, {
                    "default": "round_robin",
                    "tooltip": "API Keyè°ƒåº¦æ¨¡å¼ï¼šè½®æ¢/éšæœº/åŠ æƒ"
                }),
                
                # å¹¶è¡Œæ¨¡å¼
                "enable_parallel": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "å¯ç”¨å¹¶è¡Œæ¨¡å¼ï¼ˆåŒæ—¶ä½¿ç”¨å¤šä¸ªAPI Keyï¼‰"
                }),
                
                # é‡è¯•è®¾ç½®
                "max_retries": ("INT", {
                    "default": 3, 
                    "min": 0, 
                    "max": 10, 
                    "step": 1,
                    "tooltip": "APIè°ƒç”¨å¤±è´¥æ—¶çš„æœ€å¤§é‡è¯•æ¬¡æ•°"
                }),
                
                # è¯¦ç»†æ—¥å¿—
                "enable_detailed_logs": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "å¯ç”¨è¯¦ç»†çš„ä»»åŠ¡æ‰§è¡Œæ—¥å¿—"
                }),
                
                # Keyç®¡ç†æ¨¡å¼
                "key_management_mode": (["\u4f7f\u7528\u8f93\u5165\u7684Key", "\u4f7f\u7528\u914d\u7f6e\u6587\u4ef6Key", "\u540c\u65f6\u4f7f\u7528\u4e24\u8005"], {
                    "default": default_key_management_mode,
                    "tooltip": "é€‰æ‹©API Keyä½¿ç”¨æ¨¡å¼"
                }),
                
                # å®æ—¶çŠ¶æ€æ›´æ–°å¼€å…³
                "auto_refresh_status": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "è‡ªåŠ¨åˆ·æ–°API KeyçŠ¶æ€ä¿¡æ¯"
                }),
                
                # é¢å¤–çš„å›¾åƒè¾“å…¥
                "image2": ("IMAGE",),
                "image3": ("IMAGE",),
                "image4": ("IMAGE",),
            },
        }
        
        return input_types
    
    @classmethod
    def get_key_status_info(cls, key_management_mode: str = None) -> str:
        """è·å–å½“å‰API KeyçŠ¶æ€ä¿¡æ¯çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²"""
        try:
            managers = cls._get_managers()
            if managers is None or None in managers:
                return "ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥"
                
            config_manager, api_key_manager, _ = managers
            if not config_manager or not api_key_manager:
                return "ç®¡ç†å™¨ä¸å¯ç”¨"
                
            stats = api_key_manager.get_key_statistics()
            
            if not stats["key_details"]:
                return "æš‚æ— API KeyçŠ¶æ€ä¿¡æ¯"
            
            status_lines = []

            # æ ¹æ®ç®¡ç†æ¨¡å¼æ·»åŠ è¯´æ˜
            if key_management_mode:
                status_lines.append(f"å½“å‰æ¨¡å¼: {key_management_mode}")

            status_lines.append(f"æ€»è®¡: {stats['total_keys']}ä¸ª Key, å¯ç”¨: {stats['available_keys']}ä¸ª")
            
            for i, key_detail in enumerate(stats["key_details"][:5]):  # æœ€å¤šæ˜¾ç¤º5ä¸ª
                status_icon = "âœ…" if key_detail['status'] == 'available' else "âŒ"
                
                # æ„å»ºçŠ¶æ€æ–‡æœ¬
                status_text = f"{status_icon} Key{i+1}({key_detail['name']}): {key_detail['status']}"
                
                # æ·»åŠ ä½™é¢ä¿¡æ¯
                remaining = key_detail.get('remaining', 'æœªçŸ¥')
                if remaining != 'æœªçŸ¥':
                    if remaining == "unlimited":
                        status_text += f" | ä½™é¢:æ— é™åˆ¶"
                    else:
                        status_text += f" | ä½™é¢:{remaining}"
                
                # æ·»åŠ ä½¿ç”¨æƒ…å†µ
                usage = key_detail.get('usage', 0)
                if usage > 0:
                    status_text += f" | å·²ç”¨:{usage}"
                
                # æ·»åŠ æˆåŠŸç‡
                if key_detail['success_rate'] > 0:
                    status_text += f" | æˆåŠŸç‡:{key_detail['success_rate']}%"
                
                # æ·»åŠ å…è´¹å±‚æ ‡è¯†
                if key_detail.get('is_free_tier', False):
                    status_text += f" | ğŸ†“å…è´¹å±‚"
                
                status_lines.append(status_text)
            
            return "\n".join(status_lines)
            
        except Exception as e:
            return f"è·å–çŠ¶æ€ä¿¡æ¯å¤±è´¥: {e}"
    
    @classmethod
    def debug_managers(cls):
        """è°ƒè¯•ç®¡ç†å™¨çŠ¶æ€"""
        print("[DEBUG] æ£€æŸ¥ç®¡ç†å™¨çŠ¶æ€...")
        print(f"[DEBUG] _config_manager: {cls._config_manager}")
        print(f"[DEBUG] _api_key_manager: {cls._api_key_manager}")
        print(f"[DEBUG] _task_logger: {cls._task_logger}")
        
        try:
            managers = cls._get_managers()
            print(f"[DEBUG] _get_managers() è¿”å›: {managers}")
            if managers and len(managers) == 3:
                config_manager, api_key_manager, task_logger = managers
                print(f"[DEBUG] è§£åŒ…å: config={config_manager}, api={api_key_manager}, logger={task_logger}")
        except Exception as e:
            print(f"[DEBUG] _get_managers() å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
    
    @classmethod
    def refresh_key_status(cls):
        """åˆ·æ–°API KeyçŠ¶æ€ä¿¡æ¯"""
        try:
            config_manager, api_key_manager, _ = cls._get_managers()
            # å…ˆæ¸…ç†è¿‡æœŸå†·å´
            api_key_manager.cleanup_expired_cooldowns()
            # ç„¶ååˆ·æ–°æ‰€æœ‰KeyçŠ¶æ€
            results = api_key_manager.refresh_all_keys_status()
            return results
        except Exception as e:
            print(f"[ERROR] åˆ·æ–°KeyçŠ¶æ€å¤±è´¥: {e}")
            return {}

    def _call_openrouter(self, task_logger, log_id: str, api_key_config: Dict[str, Any], 
                        pil_refs: List[Image.Image], prompt_text: str, 
                        site_url: str, site_name: str, model: str) -> Tuple[List[Image.Image], str]:
        """
        è°ƒç”¨OpenRouter APIç”Ÿæˆå›¾ç‰‡
        
        Args:
            task_logger: æ—¥å¿—è®°å½•å™¨
            log_id: ä»»åŠ¡æ—¥å¿—ID
            api_key_config: API Keyé…ç½®
            pil_refs: å‚è€ƒå›¾ç‰‡åˆ—è¡¨
            prompt_text: æç¤ºè¯
            site_url: ç½‘ç«™URL
            site_name: ç½‘ç«™åç§°
            model: æ¨¡å‹åç§°
            
        Returns:
            Tuple[List[Image.Image], str]: (ç”Ÿæˆçš„å›¾ç‰‡åˆ—è¡¨, é”™è¯¯ä¿¡æ¯)
        """
        if OpenAI is None:
            error_msg = "æœªå®‰è£… openai åº“ï¼Œè¯·å…ˆå®‰è£…ï¼špip install openai"
            task_logger.log_error(log_id, error_msg, "dependency")
            return [], error_msg
        
        api_key_value = api_key_config.get("value", "")
        api_key_id = api_key_config.get("id", "unknown")
        
        if not api_key_value:
            error_msg = "é”™è¯¯ï¼šAPI Keyä¸ºç©ºã€‚"
            task_logger.log_error(log_id, error_msg, "configuration")
            return [], error_msg

        start_time = time.time()
        
        try:
            # åˆ›å»ºOpenAIå®¢æˆ·ç«¯ï¼Œè®¾ç½®è¶…æ—¶ä»¥é˜²æ­¢æ— é™ç­‰å¾…
            client = OpenAI(
                base_url="https://openrouter.ai/api/v1", 
                api_key=api_key_value,
                timeout=30.0  # 30ç§’è¶…æ—¶ï¼Œé˜²æ­¢ç½‘ç»œè¯·æ±‚é˜»å¡UI
            )
            headers = {}
            if site_url:
                headers["HTTP-Referer"] = site_url
            if site_name:
                headers["X-Title"] = site_name

            if len(pil_refs) > 1:
                full_prompt = f"è¯·ä¸¥æ ¼æ ¹æ®è¿™äº›å›¾ç‰‡ï¼Œå¹¶ç»“åˆä»¥ä¸‹æç¤ºè¯ï¼Œç”Ÿæˆä¸€å¼ æ–°çš„å›¾ç‰‡ã€‚ä¸è¦æè¿°å›¾ç‰‡ã€‚æç¤ºè¯ï¼š'{prompt_text}'"
            else:
                full_prompt = f"è¯·ä¸¥æ ¼æ ¹æ®è¿™å¼ å›¾ç‰‡ï¼Œå¹¶ç»“åˆä»¥ä¸‹æç¤ºè¯ï¼Œç”Ÿæˆä¸€å¼ æ–°çš„å›¾ç‰‡ã€‚ä¸è¦æè¿°å›¾ç‰‡ã€‚æç¤ºè¯ï¼š'{prompt_text}'"

            content = [{"type": "text", "text": full_prompt}]
            for pil_ref in pil_refs:
                data_url = pil_to_base64_data_url(pil_ref, format="jpeg")
                content.append({"type": "image_url", "image_url": {"url": data_url}})

            # è®°å½•è¯·æ±‚æ•°æ®
            request_data = {
                "prompt": prompt_text,
                "model": model,
                "images": pil_refs,
                "image_count": len(pil_refs)
            }

            completion = client.chat.completions.create(
                extra_headers=headers,
                model=model,
                messages=[
                    {
                        "role": "user",
                        "content": content,
                    }
                ],
            )
            
            duration = time.time() - start_time
            
            pils, err = decode_image_from_openrouter_response(completion)
            if err:
                task_logger.log_api_call(log_id, api_key_id, model, request_data, None, err, duration)
                return [], err
            if not pils:
                error_msg = "æœªä»æ¨¡å‹æ”¶åˆ°å›¾ç‰‡æ•°æ®ã€‚"
                task_logger.log_api_call(log_id, api_key_id, model, request_data, None, error_msg, duration)
                return [], error_msg
            
            # è®°å½•æˆåŠŸçš„APIè°ƒç”¨ï¼ŒåŒ…å«å®é™…æ˜¾ç¤ºæ•°é‡
            actual_display_count = get_actual_display_count(pils)
            response_data = {
                "images_generated": len(pils),
                "images_displayed": actual_display_count,
                "images_info": [f"image_{i}" for i in range(len(pils))]
            }
            task_logger.log_api_call(log_id, api_key_id, model, request_data, response_data, None, duration)
            
            return pils, ""
            
        except Exception as e:
            duration = time.time() - start_time
            error_msg = f"ç”Ÿæˆå›¾ç‰‡æ—¶å‡ºé”™: {str(e)}"
            
            # è®°å½•å¤±è´¥çš„APIè°ƒç”¨
            request_data = {
                "prompt": prompt_text,
                "model": model,
                "images": pil_refs,
                "image_count": len(pil_refs)
            }
            task_logger.log_api_call(log_id, api_key_id, model, request_data, None, error_msg, duration)
            
            return [], error_msg
    
    def _process_single_prompt(self, managers: Tuple, log_id: str, 
                              pil_refs: List[Image.Image], prompt_text: str,
                              site_url: str, site_name: str, model: str,
                              max_retries: int) -> Tuple[List[Image.Image], str]:
        """
        å¤„ç†å•ä¸ªæç¤ºè¯çš„å›¾ç‰‡ç”Ÿæˆ
        
        Args:
            managers: ç®¡ç†å™¨å…ƒç»„ (config_manager, api_key_manager, task_logger)
            log_id: ä»»åŠ¡æ—¥å¿—ID
            pil_refs: å‚è€ƒå›¾ç‰‡åˆ—è¡¨
            prompt_text: æç¤ºè¯
            site_url: ç½‘ç«™URL
            site_name: ç½‘ç«™åç§°
            model: æ¨¡å‹åç§°
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            
        Returns:
            Tuple[List[Image.Image], str]: (ç”Ÿæˆçš„å›¾ç‰‡åˆ—è¡¨, é”™è¯¯ä¿¡æ¯)
        """
        config_manager, api_key_manager, task_logger = managers
        
        for attempt in range(max_retries + 1):
            # é€‰æ‹©API Key
            api_key_config = api_key_manager.get_best_key_for_model(model)
            if not api_key_config:
                error_msg = "æ²¡æœ‰å¯ç”¨çš„API Keyã€‚è¯·æ£€æŸ¥é…ç½®æˆ–ç­‰å¾…å†·å´æœŸç»“æŸã€‚"
                if attempt > 0:
                    task_logger.log_retry(log_id, attempt, "æ²¡æœ‰å¯ç”¨çš„API Key")
                task_logger.log_error(log_id, error_msg, "api_key")
                return [], error_msg
            
            if attempt > 0:
                task_logger.log_retry(log_id, attempt, f"ä½¿ç”¨API Key: {api_key_config.get('name', 'Unknown')}")
            
            # è°ƒç”¨API
            pils, error = self._call_openrouter(
                task_logger, log_id, api_key_config, pil_refs, 
                prompt_text, site_url, site_name, model
            )
            
            if not error:
                # æˆåŠŸï¼Œæ›´æ–°API Keyç»Ÿè®¡
                api_key_manager.update_key_stats(api_key_config["id"], True)
                return pils, ""
            
            # å¤±è´¥ï¼Œæ›´æ–°API Keyç»Ÿè®¡å¹¶æ ‡è®°é”™è¯¯
            api_key_manager.update_key_stats(api_key_config["id"], False)
            api_key_manager.mark_key_error(api_key_config["id"], "error", error)
            
            # å¦‚æœè¿™æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œè¿”å›é”™è¯¯
            if attempt >= max_retries:
                return [], error
        
        return [], "è¶…å‡ºæœ€å¤§é‡è¯•æ¬¡æ•°"
    
    def _process_single_prompt_with_key(self, managers: Tuple, log_id: str,
                                       pil_refs: List[Image.Image], prompt_text: str,
                                       site_url: str, site_name: str, model: str,
                                       max_retries: int, assigned_key: Dict[str, Any]) -> Tuple[List[Image.Image], str]:
        """
        ä½¿ç”¨æŒ‡å®šAPI Keyå¤„ç†å•ä¸ªæç¤ºè¯çš„å›¾ç‰‡ç”Ÿæˆ
        
        Args:
            managers: ç®¡ç†å™¨å…ƒç»„ (config_manager, api_key_manager, task_logger)
            log_id: ä»»åŠ¡æ—¥å¿—ID
            pil_refs: å‚è€ƒå›¾ç‰‡åˆ—è¡¨
            prompt_text: æç¤ºè¯
            site_url: ç½‘ç«™URL
            site_name: ç½‘ç«™åç§°
            model: æ¨¡å‹åç§°
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            assigned_key: æŒ‡å®šä½¿ç”¨çš„API Keyé…ç½®
            
        Returns:
            Tuple[List[Image.Image], str]: (ç”Ÿæˆçš„å›¾ç‰‡åˆ—è¡¨, é”™è¯¯ä¿¡æ¯)
        """
        config_manager, api_key_manager, task_logger = managers
        
        for attempt in range(max_retries + 1):
            # æ£€æŸ¥æŒ‡å®šKeyæ˜¯å¦ä»ç„¶å¯ç”¨
            if not api_key_manager.is_key_available(assigned_key["id"]):
                error_msg = f"æŒ‡å®šAPI Key {assigned_key.get('name', 'Unknown')} ä¸å¯ç”¨"
                if attempt > 0:
                    task_logger.log_retry(log_id, attempt, error_msg)
                task_logger.log_error(log_id, error_msg, "api_key")
                return [], error_msg
            
            if attempt > 0:
                task_logger.log_retry(log_id, attempt, f"ä½¿ç”¨API Key: {assigned_key.get('name', 'Unknown')}")
            
            # è°ƒç”¨API
            pils, error = self._call_openrouter(
                task_logger, log_id, assigned_key, pil_refs,
                prompt_text, site_url, site_name, model
            )
            
            if not error:
                # æˆåŠŸï¼Œæ›´æ–°API Keyç»Ÿè®¡
                api_key_manager.update_key_stats(assigned_key["id"], True)
                return pils, ""
            
            # å¤±è´¥ï¼Œæ›´æ–°API Keyç»Ÿè®¡å¹¶æ ‡è®°é”™è¯¯
            api_key_manager.update_key_stats(assigned_key["id"], False)
            api_key_manager.mark_key_error(assigned_key["id"], "error", error)
            
            # å¦‚æœè¿™æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œè¿”å›é”™è¯¯
            if attempt >= max_retries:
                return [], error
        
        return [], "è¶…å‡ºæœ€å¤§é‡è¯•æ¬¡æ•°"
    
    def _process_batch_concurrent(self, managers: Tuple, log_id: str,
                                 prompts: List[str], pil_refs: List[Image.Image],
                                 site_url: str, site_name: str, model: str,
                                 max_concurrent: int, max_retries: int) -> Tuple[List[Image.Image], List[str]]:
        """
        å¹¶å‘å¤„ç†æ‰¹é‡æç¤ºè¯
        
        Args:
            managers: ç®¡ç†å™¨å…ƒç»„
            log_id: ä»»åŠ¡æ—¥å¿—ID
            prompts: æç¤ºè¯åˆ—è¡¨
            pil_refs: å‚è€ƒå›¾ç‰‡åˆ—è¡¨
            site_url: ç½‘ç«™URL
            site_name: ç½‘ç«™åç§°
            model: æ¨¡å‹åç§°
            max_concurrent: æœ€å¤§å¹¶å‘æ•°
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            
        Returns:
            Tuple[List[Image.Image], List[str]]: (æ‰€æœ‰ç”Ÿæˆçš„å›¾ç‰‡, çŠ¶æ€æ¶ˆæ¯åˆ—è¡¨)
        """
        config_manager, api_key_manager, task_logger = managers
        all_images = []
        status_messages = []
        
        # è·å–å¹¶å‘ä»»åŠ¡æ‰€éœ€çš„API Key
        selected_keys = api_key_manager.select_keys_for_parallel(max_concurrent)
        if not selected_keys:
            return [], ["é”™è¯¯ï¼šæ²¡æœ‰å¯ç”¨çš„API Key"]
        
        task_logger.log_info(log_id, f"ä¸º{max_concurrent}ä¸ªå¹¶å‘ä»»åŠ¡é€‰æ‹©äº†{len(selected_keys)}ä¸ªAPI Key")
        
        with ThreadPoolExecutor(max_workers=max_concurrent) as executor:
            try:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_info = {}
                for i, prompt_text in enumerate(prompts):
                    if not prompt_text or not prompt_text.strip():
                        status_messages.append(f"ç¬¬ {i + 1} è¡Œè·³è¿‡ï¼šç©ºæç¤ºè¯")
                        continue
                    
                    # ä¸ºæ¯ä¸ªä»»åŠ¡åˆ†é…ä¸€ä¸ªAPI Keyï¼ˆè½®æ¢ä½¿ç”¨ï¼‰
                    assigned_key = selected_keys[i % len(selected_keys)]
                    
                    future = executor.submit(
                        self._process_single_prompt_with_key,
                        managers, log_id, pil_refs, prompt_text.strip(),
                        site_url, site_name, model, max_retries, assigned_key
                    )
                    future_to_info[future] = {
                        "index": i,
                        "key_name": assigned_key.get("name", "Unknown"),
                        "key_id": assigned_key.get("id", "Unknown")
                    }
                
                # æ”¶é›†ç»“æœï¼ˆä¿®å¤è¶…æ—¶æœºåˆ¶å’Œå›¾ç‰‡ä¿å­˜é€»è¾‘ï¼‰
                completed_futures = set()
                try:
                    # ä½¿ç”¨æ›´é•¿çš„æ€»è¶…æ—¶æ—¶é—´ï¼Œä½†åˆ†æ‰¹å¤„ç†
                    for future in as_completed(future_to_info, timeout=60):  # å¢åŠ åˆ°60ç§’æ€»è¶…æ—¶
                        completed_futures.add(future)
                        info = future_to_info[future]
                        index = info["index"]
                        key_name = info["key_name"]

                        try:
                            pils, error = future.result(timeout=30)  # å¢åŠ å•ä¸ªä»»åŠ¡è¶…æ—¶åˆ°30ç§’
                            if error:
                                status_messages.append(f"å›¾ç‰‡ {index + 1} ç”Ÿæˆå¤±è´¥ï¼ˆä½¿ç”¨Key: {key_name}ï¼‰ï¼š{error}")
                            else:
                                all_images.extend(pils)
                                # è®¡ç®—å®é™…æ˜¾ç¤ºçš„å›¾ç‰‡æ•°é‡
                                actual_display_count = get_actual_display_count(pils)

                                # ä¿®å¤ï¼šå§‹ç»ˆä¿å­˜ç”Ÿæˆçš„å›¾ç‰‡åˆ°è¾“å‡ºç›®å½•
                                saved_paths = []
                                try:
                                    # ä¿å­˜æ‰€æœ‰ç”Ÿæˆçš„å›¾ç‰‡ï¼ˆä¸ä»…ä»…æ˜¯å°ºå¯¸ä¸åŒ¹é…çš„ï¼‰
                                    saved_paths = save_images_to_output(
                                        pils,
                                        task_id=log_id or f"concurrent_{index+1}",
                                        prompt=f"å¹¶å‘ä»»åŠ¡{index+1}"
                                    )

                                    # è®°å½•ä¿å­˜è·¯å¾„åˆ°æ—¥å¿—
                                    if saved_paths and log_id:
                                        config_manager, api_key_manager, task_logger = managers
                                        if task_logger:
                                            task_logger.log_info(
                                                log_id,
                                                f"å›¾ç‰‡å·²ä¿å­˜: {', '.join(saved_paths)}"
                                            )
                                except Exception as save_error:
                                    print(f"[WARNING] ä¿å­˜å›¾ç‰‡å¤±è´¥: {save_error}")
                                    status_messages.append(f"å›¾ç‰‡ {index + 1} ä¿å­˜å¤±è´¥: {save_error}")

                                # ç”ŸæˆçŠ¶æ€æ¶ˆæ¯
                                if len(pils) == actual_display_count:
                                    save_info = f"ï¼Œå·²ä¿å­˜åˆ°è¾“å‡ºç›®å½•" if saved_paths else ""
                                    status_messages.append(f"å›¾ç‰‡ {index + 1} ç”ŸæˆæˆåŠŸï¼ˆä½¿ç”¨Key: {key_name}ï¼Œ{len(pils)} å¼ {save_info}ï¼‰ã€‚")
                                else:
                                    # æä¾›ä¿å­˜ä¿¡æ¯
                                    save_info = f"ï¼Œå·²ä¿å­˜åˆ°è¾“å‡ºç›®å½•" if saved_paths else ""
                                    status_messages.append(
                                        f"å›¾ç‰‡ {index + 1} ç”ŸæˆæˆåŠŸï¼ˆä½¿ç”¨Key: {key_name}ï¼Œ"
                                        f"ç”Ÿæˆ{len(pils)}å¼ ï¼Œæ˜¾ç¤º{actual_display_count}å¼ {save_info}ï¼‰ã€‚"
                                    )
                        except Exception as e:
                            error_msg = f"å›¾ç‰‡ {index + 1} å¤„ç†å¼‚å¸¸ï¼ˆä½¿ç”¨Key: {key_name}ï¼‰ï¼š{e}"
                            status_messages.append(error_msg)
                            print(f"[ERROR] {error_msg}")

                except Exception as timeout_error:
                    # å¤„ç†è¶…æ—¶å¼‚å¸¸ï¼Œæ£€æŸ¥æœªå®Œæˆçš„futures
                    unfinished_count = len(future_to_info) - len(completed_futures)
                    if unfinished_count > 0:
                        timeout_msg = f"å¹¶å‘å¤„ç†è¶…æ—¶: {unfinished_count} (of {len(future_to_info)}) futures unfinished"
                        status_messages.append(timeout_msg)
                        print(f"[WARNING] {timeout_msg}")

                        # è°ƒè¯•å¹¶å‘çŠ¶æ€
                        self._debug_concurrent_status(future_to_info, completed_futures, log_id)

                        # å°è¯•è·å–æœªå®Œæˆä»»åŠ¡çš„ç»“æœï¼ˆéé˜»å¡ï¼‰
                        for future in future_to_info:
                            if future not in completed_futures:
                                info = future_to_info[future]
                                try:
                                    # éé˜»å¡æ£€æŸ¥
                                    if future.done():
                                        pils, error = future.result(timeout=0.1)
                                        if not error and pils:
                                            all_images.extend(pils)
                                            # ä¿å­˜è¿™äº›å›¾ç‰‡
                                            try:
                                                saved_paths = save_images_to_output(
                                                    pils,
                                                    task_id=log_id or f"timeout_recovered_{info['index']+1}",
                                                    prompt=f"è¶…æ—¶æ¢å¤ä»»åŠ¡{info['index']+1}"
                                                )
                                                if saved_paths:
                                                    status_messages.append(f"å›¾ç‰‡ {info['index'] + 1} è¶…æ—¶åæ¢å¤æˆåŠŸï¼Œå·²ä¿å­˜")
                                            except:
                                                pass
                                except:
                                    pass
                        
            except Exception as e:
                error_msg = f"å¹¶å‘å¤„ç†å¼‚å¸¸: {e}"
                status_messages.append(error_msg)
                print(f"[ERROR] {error_msg}")
            finally:
                # æ”¹è¿›çš„çº¿ç¨‹æ± æ¸…ç†é€»è¾‘
                try:
                    # ç»Ÿè®¡æœªå®Œæˆçš„ä»»åŠ¡
                    unfinished_futures = []
                    for future in future_to_info:
                        if not future.done():
                            unfinished_futures.append(future)

                    if unfinished_futures:
                        print(f"[INFO] æ­£åœ¨æ¸…ç† {len(unfinished_futures)} ä¸ªæœªå®Œæˆçš„ä»»åŠ¡...")

                        # å°è¯•å–æ¶ˆæœªå®Œæˆçš„ä»»åŠ¡
                        cancelled_count = 0
                        for future in unfinished_futures:
                            if future.cancel():
                                cancelled_count += 1

                        print(f"[INFO] æˆåŠŸå–æ¶ˆ {cancelled_count}/{len(unfinished_futures)} ä¸ªä»»åŠ¡")

                    # ä¼˜é›…å…³é—­çº¿ç¨‹æ± 
                    executor.shutdown(wait=False)

                except Exception as shutdown_error:
                    print(f"[WARNING] çº¿ç¨‹æ± æ¸…ç†å¼‚å¸¸: {shutdown_error}")
        
        return all_images, status_messages

    def _process_concurrent_prompts(self, managers: Tuple, log_id: str,
                                  prompts: List[str], pil_refs: List[Image.Image],
                                  site_url: str, site_name: str, model: str,
                                  max_concurrent: int, max_retries: int) -> Tuple[List[Image.Image], List[str]]:
        """
        å¹¶å‘å¤„ç†å¤šä¸ªæç¤ºè¯ï¼ˆä¸»è¦ç”¨äºå•æ¡promptçš„å¹¶å‘ç”Ÿæˆï¼‰
        
        Args:
            managers: ç®¡ç†å™¨å…ƒç»„
            log_id: ä»»åŠ¡æ—¥å¿—ID
            prompts: æç¤ºè¯åˆ—è¡¨
            pil_refs: å‚è€ƒå›¾ç‰‡åˆ—è¡¨
            site_url: ç½‘ç«™URL
            site_name: ç½‘ç«™åç§°
            model: æ¨¡å‹åç§°
            max_concurrent: æœ€å¤§å¹¶å‘æ•°
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            
        Returns:
            Tuple[List[Image.Image], List[str]]: (æ‰€æœ‰ç”Ÿæˆçš„å›¾ç‰‡, çŠ¶æ€æ¶ˆæ¯åˆ—è¡¨)
        """
        # å¤ç”¨å·²æœ‰çš„æ‰¹é‡å¹¶å‘å¤„ç†é€»è¾‘
        return self._process_batch_concurrent(
            managers, log_id, prompts, pil_refs,
            site_url, site_name, model, max_concurrent, max_retries
        )
    
    def _debug_concurrent_status(self, future_to_info: dict, completed_futures: set, log_id: str = None):
        """
        è°ƒè¯•å¹¶å‘å¤„ç†çŠ¶æ€

        Args:
            future_to_info: Futureåˆ°ä¿¡æ¯çš„æ˜ å°„
            completed_futures: å·²å®Œæˆçš„Futureé›†åˆ
            log_id: æ—¥å¿—ID
        """
        try:
            total_futures = len(future_to_info)
            completed_count = len(completed_futures)
            pending_count = total_futures - completed_count

            debug_msg = f"å¹¶å‘çŠ¶æ€: æ€»ä»»åŠ¡={total_futures}, å·²å®Œæˆ={completed_count}, å¾…å®Œæˆ={pending_count}"
            print(f"[DEBUG] {debug_msg}")

            if log_id:
                managers = self._get_managers()
                if managers and managers[2]:  # task_logger
                    task_logger = managers[2]
                    task_logger.log_info(log_id, debug_msg)

            # è¯¦ç»†çŠ¶æ€
            for future, info in future_to_info.items():
                status = "completed" if future in completed_futures else ("done" if future.done() else "pending")
                print(f"[DEBUG] Task {info['index']+1} ({info['key_name']}): {status}")

        except Exception as e:
            print(f"[WARNING] è°ƒè¯•çŠ¶æ€æ£€æŸ¥å¤±è´¥: {e}")

    def _cleanup_resources(self, pil_images=None):
        """
        æ¸…ç†èµ„æºï¼Œé˜²æ­¢å†…å­˜æ³„æ¼å’ŒUIå‡æ­»

        Args:
            pil_images: PILå›¾åƒåˆ—è¡¨ï¼Œå¯é€‰
        """
        try:
            # æ¸…ç†PILå›¾åƒå¯¹è±¡
            if pil_images:
                for img in pil_images:
                    if hasattr(img, 'close'):
                        try:
                            img.close()
                        except:
                            pass

            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            import gc
            gc.collect()

            # å¼ºåˆ¶ä¿å­˜å¾…å­˜æ—¥å¿—
            try:
                managers = self._get_managers()
                if managers and managers[2]:  # task_logger
                    task_logger = managers[2]
                    if hasattr(task_logger, '_save_pending') and task_logger._save_pending:
                        task_logger._save_task_logs(force=True)
            except:
                pass

        except Exception as e:
            print(f"[WARNING] èµ„æºæ¸…ç†å¼‚å¸¸: {e}")

    def generate(
        self,
        api_key_main: str,
        image1=None,
        prompt: str = "",
        file_path: str = "",
        site_url: str = "",
        site_name: str = "",
        model: str = "google/gemini-2.5-flash-image-preview:free",
        max_concurrent: int = 3,
        scheduling_mode: str = "round_robin",
        enable_parallel: bool = False,
        max_retries: int = 3,
        enable_detailed_logs: bool = True,
        key_management_mode: str = "åŒæ—¶ä½¿ç”¨ä¸¤è€…",
        auto_refresh_status: bool = True,
        image2=None,
        image3=None,
        image4=None,
        **kwargs  # æ•è·æ‰€æœ‰é¢å¤–çš„api_key_Xå‚æ•°
    ):
        """
        æ–°ç‰ˆæœ¬çš„å›¾ç‰‡ç”Ÿæˆæ–¹æ³•ï¼Œæ”¯æŒå¹¶å‘ã€å¤šKeyç®¡ç†å’Œè¯¦ç»†æ—¥å¿—
        """
        # è·å–ç®¡ç†å™¨å®ä¾‹
        try:
            managers = self._get_managers()
            if managers is None or None in managers:
                error_msg = "ç®¡ç†å™¨åˆå§‹åŒ–è¿”å›None"
                print(f"è­¦å‘Š: {error_msg}")
                return (pils_to_tensor([]), error_msg, "ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥")
                
            config_manager, api_key_manager, task_logger = managers
        except Exception as e:
            error_msg = f"åˆå§‹åŒ–ç®¡ç†å™¨å¤±è´¥: {e}"
            print(f"è­¦å‘Š: {error_msg}")
            import traceback
            traceback.print_exc()
            # åœ¨ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥æ—¶è¿”å›é”™è¯¯ï¼Œé¿å…åç»­ä½¿ç”¨Noneå¯¹è±¡
            return (pils_to_tensor([]), error_msg, "ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥")
        
        # éªŒè¯ç®¡ç†å™¨æ˜¯å¦æ­£ç¡®åˆå§‹åŒ–
        if not all([config_manager, api_key_manager, task_logger]):
            error_msg = "ç®¡ç†å™¨åˆå§‹åŒ–ä¸å®Œæ•´"
            print(f"è­¦å‘Š: {error_msg} - config:{config_manager}, api:{api_key_manager}, logger:{task_logger}")
            return (pils_to_tensor([]), error_msg, "ç®¡ç†å™¨åˆå§‹åŒ–ä¸å®Œæ•´")

        # ä¿å­˜ç”¨æˆ·é€‰æ‹©çš„key_management_modeåˆ°é…ç½®æ–‡ä»¶ï¼ˆå¦‚æœä¸å½“å‰é…ç½®ä¸åŒï¼‰
        current_mode = config_manager.get_setting("key_management_mode", "åŒæ—¶ä½¿ç”¨ä¸¤è€…")
        if key_management_mode != current_mode:
            try:
                config_manager.update_setting("key_management_mode", key_management_mode)
                print(f"[INFO] Keyç®¡ç†æ¨¡å¼å·²æ›´æ–°ä¸º: {key_management_mode}")
            except Exception as e:
                print(f"[WARNING] ä¿å­˜Keyç®¡ç†æ¨¡å¼å¤±è´¥: {e}")
        
        # åˆ›å»ºä»»åŠ¡ID
        task_id = str(uuid.uuid4())[:8]
        
        # åŠ¨æ€æ›´æ–°API KeyçŠ¶æ€æ˜¾ç¤ºä¿¡æ¯ï¼ˆåœ¨Keyç®¡ç†æ¨¡å¼å¤„ç†ä¹‹åï¼‰
        current_key_status = ""
        
        # éªŒè¯å’Œè½¬æ¢è¾“å…¥å›¾åƒ
        try:
            all_input_pils = validate_and_convert_images([image1, image2, image3, image4])
        except ValueError as e:
            return (pils_to_tensor([]), str(e), "å›¾åƒéªŒè¯å¤±è´¥")
        
        # åˆ›å»ºä»»åŠ¡æ—¥å¿—ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        log_id = None
        if enable_detailed_logs:
            task_data = {
                "prompt": prompt,
                "file_path": file_path,
                "model": model,
                "max_concurrent": max_concurrent,
                "max_retries": max_retries,
                "input_images": len(all_input_pils)
            }
            
            if prompt and file_path:
                task_type = "mixed"
            elif file_path:
                task_type = "batch"
            else:
                task_type = "single"
            
            log_id = task_logger.create_task_log(task_id, task_type, task_data)
            task_logger.update_task_status(log_id, TaskStatus.RUNNING)
        
        # å¤„ç†å¤šä¸ªAPI Keyè¾“å…¥
        input_api_keys = []
        
        # æ·»åŠ ä¸»Key
        if api_key_main and api_key_main.strip():
            input_api_keys.append({
                "name": "Main Key",
                "value": api_key_main.strip(),
                "source": "input"
            })
        
        # æ·»åŠ é¢å¤–çš„Keyï¼ˆä»**kwargsä¸­è·å–ï¼‰
        for key, value in kwargs.items():
            if key.startswith('api_key_') and value and value.strip():
                key_num = key.replace('api_key_', '')
                input_api_keys.append({
                    "name": f"Key {key_num}",
                    "value": value.strip(),
                    "source": "input"
                })
        
        # è®°å½•ä¸´æ—¶æ·»åŠ çš„Key ID
        temp_key_ids = []

        # æ ¹æ®ç®¡ç†æ¨¡å¼å¤„ç†API Keys
        if key_management_mode == "ä½¿ç”¨è¾“å…¥çš„Key":
            # ä»…ä½¿ç”¨è¾“å…¥çš„Key
            if not input_api_keys:
                return (pils_to_tensor([]), "é”™è¯¯ï¼šè¯·è‡³å°‘è¾“å…¥ä¸€ä¸ªAPI Key", "æ— API Key")

            print(f"[INFO] ä½¿ç”¨è¾“å…¥çš„Keyæ¨¡å¼ï¼Œå°†ä½¿ç”¨ {len(input_api_keys)} ä¸ªè¾“å…¥Keyï¼ˆä»…å†…å­˜å­˜å‚¨ï¼‰")

            # è®¾ç½®ä¸´æ—¶Keyæ¨¡å¼
            config_manager.set_temp_key_mode(key_management_mode)

            # æ·»åŠ è¾“å…¥çš„Keyä½œä¸ºä¸´æ—¶Keyï¼ˆä»…å†…å­˜ï¼Œä¸ä¿å­˜åˆ°æ–‡ä»¶ï¼‰
            for key_info in input_api_keys:
                key_id = config_manager.add_temp_key(key_info["name"], key_info["value"])
                temp_key_ids.append(key_id)

            # è®¾ç½®ApiKeyManagerçš„ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿åªæ˜¾ç¤ºè¾“å…¥Keyçš„çŠ¶æ€
            api_key_manager.set_key_context(key_management_mode, temp_key_ids)

        elif key_management_mode == "ä½¿ç”¨é…ç½®æ–‡ä»¶Key":
            # ä»…ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„Keyï¼Œå¿½ç•¥è¾“å…¥çš„Key
            config_manager.set_temp_key_mode(key_management_mode)
            existing_keys = config_manager.get_api_keys()
            if not existing_keys:
                return (pils_to_tensor([]), "é”™è¯¯ï¼šé…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰å¯ç”¨çš„API Key", "é…ç½®ä¸­æ— Key")
            print(f"[INFO] ä½¿ç”¨é…ç½®æ–‡ä»¶Keyæ¨¡å¼ï¼Œå¿½ç•¥ {len(input_api_keys)} ä¸ªè¾“å…¥Key")

            # è®¾ç½®ApiKeyManagerçš„ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿åªæ˜¾ç¤ºé…ç½®æ–‡ä»¶Keyçš„çŠ¶æ€
            api_key_manager.set_key_context(key_management_mode, [])

        else:  # "åŒæ—¶ä½¿ç”¨ä¸¤è€…"
            # åŒæ—¶ä½¿ç”¨è¾“å…¥å’Œé…ç½®æ–‡ä»¶ä¸­çš„Key
            config_manager.set_temp_key_mode(key_management_mode)

            # æ·»åŠ è¾“å…¥Keyä½œä¸ºä¸´æ—¶Keyï¼ˆä¸ä¿å­˜åˆ°é…ç½®æ–‡ä»¶ï¼‰
            for key_info in input_api_keys:
                key_id = config_manager.add_temp_key(key_info["name"], key_info["value"])
                temp_key_ids.append(key_id)

            # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„Key
            all_keys = config_manager.get_api_keys()
            if not all_keys:
                return (pils_to_tensor([]), "é”™è¯¯ï¼šè¯·è¾“å…¥API Keyæˆ–åœ¨é…ç½®æ–‡ä»¶ä¸­é…ç½®", "æ— å¯ç”¨Key")

            # è®¾ç½®ApiKeyManagerçš„ä¸Šä¸‹æ–‡ï¼Œæ˜¾ç¤ºæ‰€æœ‰Keyçš„çŠ¶æ€
            api_key_manager.set_key_context(key_management_mode, temp_key_ids)

        # åœ¨Keyç®¡ç†æ¨¡å¼å¤„ç†å®Œæˆåï¼Œåˆ·æ–°å½“å‰å¯ç”¨Keyçš„çŠ¶æ€
        if auto_refresh_status:
            try:
                current_keys = config_manager.get_api_keys()
                print(f"[INFO] æ­£åœ¨åˆ·æ–°å½“å‰ {len(current_keys)} ä¸ªAPI Keyçš„çŠ¶æ€...")

                # åªåˆ·æ–°å½“å‰é…ç½®ä¸­çš„Keyï¼ˆå·²ç»æ ¹æ®ç®¡ç†æ¨¡å¼è¿‡æ»¤ï¼‰
                refresh_results = self.refresh_key_status()
                print(f"[INFO] KeyçŠ¶æ€åˆ·æ–°å®Œæˆ: {refresh_results}")

                # è·å–çŠ¶æ€ä¿¡æ¯
                current_key_status = self.get_key_status_info(key_management_mode)
            except Exception as e:
                current_key_status = f"è·å–çŠ¶æ€ä¿¡æ¯å¤±è´¥: {e}"
                print(f"[WARNING] KeyçŠ¶æ€åˆ·æ–°å¤±è´¥: {e}")

        try:
            all_out_pils = []
            status_msgs = []
            
            # å•æ¡ prompt å¤„ç†ï¼ˆæ”¯æŒå¹¶å‘ç”Ÿæˆå¤šå¼ å›¾ç‰‡ï¼‰
            if prompt:
                if max_concurrent > 1:
                    # å¹¶å‘æ¨¡å¼ï¼šç”Ÿæˆå¤šå¼ å›¾ç‰‡
                    prompts = [prompt] * max_concurrent  # å¤åˆ¶promptä»¥æ”¯æŒå¹¶å‘
                    batch_pils, batch_msgs = self._process_concurrent_prompts(
                        managers, log_id or "", prompts, all_input_pils,
                        site_url, site_name, model, max_concurrent, max_retries
                    )
                    all_out_pils.extend(batch_pils)
                    status_msgs.extend(batch_msgs)
                    if not batch_pils:
                        error_msg = "å¹¶å‘ç”Ÿæˆå¤±è´¥ï¼Œæœªç”Ÿæˆä»»ä½•å›¾ç‰‡"
                        if log_id:
                            task_logger.update_task_status(log_id, TaskStatus.FAILED, error_msg)
                        return (pils_to_tensor(all_input_pils), error_msg, "å¹¶å‘å¤„ç†å¤±è´¥")
                else:
                    # å•å¼ æ¨¡å¼ï¼šä»…ç”Ÿæˆä¸€å¼ å›¾ç‰‡
                    pils, error = self._process_single_prompt(
                        managers, log_id or "", all_input_pils, prompt,
                        site_url, site_name, model, max_retries
                    )
                    if error:
                        if log_id:
                            task_logger.update_task_status(log_id, TaskStatus.FAILED, error)
                        return (pils_to_tensor(all_input_pils), error, "å•å›¾ç”Ÿæˆå¤±è´¥")
                    
                    all_out_pils.extend(pils)
                    # è®¡ç®—å®é™…æ˜¾ç¤ºçš„å›¾ç‰‡æ•°é‡
                    actual_display_count = get_actual_display_count(pils)

                    # ä¿®å¤ï¼šå§‹ç»ˆä¿å­˜ç”Ÿæˆçš„å›¾ç‰‡åˆ°è¾“å‡ºç›®å½•
                    saved_paths = []
                    try:
                        saved_paths = save_images_to_output(
                            pils,
                            task_id=log_id or "single_prompt",
                            prompt=prompt[:50] if prompt else "å•å›¾ç”Ÿæˆ"  # é™åˆ¶æç¤ºè¯é•¿åº¦
                        )

                        # è®°å½•ä¿å­˜è·¯å¾„åˆ°æ—¥å¿—
                        if saved_paths and log_id:
                            task_logger.log_info(
                                log_id,
                                f"å›¾ç‰‡å·²ä¿å­˜: {', '.join(saved_paths)}"
                            )
                    except Exception as save_error:
                        print(f"[WARNING] ä¿å­˜å›¾ç‰‡å¤±è´¥: {save_error}")
                        status_msgs.append(f"å›¾ç‰‡ä¿å­˜å¤±è´¥: {save_error}")

                    # ç”ŸæˆçŠ¶æ€æ¶ˆæ¯
                    save_info = f"ï¼Œå·²ä¿å­˜åˆ°è¾“å‡ºç›®å½•" if saved_paths else ""
                    if len(pils) == actual_display_count:
                        status_msgs.append(f"å·²ç”Ÿæˆ {len(pils)} å¼ å›¾ç‰‡{save_info}ã€‚")
                    else:
                        status_msgs.append(f"å·²ç”Ÿæˆ {len(pils)} å¼ å›¾ç‰‡ï¼Œæ˜¾ç¤º {actual_display_count} å¼ {save_info}ã€‚")
            
            # æ‰¹é‡æ–‡ä»¶å¤„ç† 
            elif file_path:
                batch_pils, batch_msgs = self._process_batch_file(
                    managers, log_id or "", all_input_pils, file_path,
                    site_url, site_name, model, max_concurrent, max_retries
                )
                all_out_pils.extend(batch_pils)
                status_msgs.extend(batch_msgs)
            
            if not all_out_pils:
                error_msg = "æœªç”Ÿæˆä»»ä½•å›¾ç‰‡ã€‚"
                if log_id:
                    task_logger.update_task_status(log_id, TaskStatus.FAILED, error_msg)
                return (pils_to_tensor(all_input_pils), error_msg + "\n" + "\n".join(status_msgs), "ç”Ÿæˆå¤±è´¥")
            
            # æˆåŠŸå®Œæˆ
            if log_id:
                task_logger.update_task_status(log_id, TaskStatus.SUCCESS)
                # å¼ºåˆ¶ä¿å­˜æ—¥å¿—ï¼Œç¡®ä¿ä»»åŠ¡å®ŒæˆçŠ¶æ€è¢«è®°å½•
                task_logger._save_task_logs(force=True)
            
            # æ¸…ç†ä¸´æ—¶æ·»åŠ çš„Keyï¼ˆå¦‚æœéœ€è¦ï¼‰
            if key_management_mode in ["ä½¿ç”¨è¾“å…¥çš„Key", "åŒæ—¶ä½¿ç”¨ä¸¤è€…"] and input_api_keys:
                # ä»…åœ¨ä½¿ç”¨è¾“å…¥Keyæ—¶æ¸…ç†ä¸´æ—¶Key
                cleaned_count = config_manager.cleanup_temporary_keys()
                if cleaned_count > 0:
                    status_msgs.append(f"å·²æ¸…ç† {cleaned_count} ä¸ªä¸´æ—¶API Key")
            
            # è½¬æ¢è¾“å‡ºç»“æœ
            out_tensor = pils_to_tensor(all_out_pils)
            
            # æ£€æŸ¥å°ºå¯¸ä¸åŒ¹é…é—®é¢˜
            size_info = create_size_mismatch_message(all_out_pils)
            
            # ç»„åˆçŠ¶æ€ä¿¡æ¯ï¼ˆåŒ…å«API KeyçŠ¶æ€ï¼‰
            final_status = ("\n".join(status_msgs) + size_info) if status_msgs else ("å®Œæˆ" + size_info)
            
            # è·å–å®æ—¶KeyçŠ¶æ€ä¿¡æ¯
            final_key_status = self.get_key_status_info(key_management_mode) if auto_refresh_status else current_key_status
            
            # æ¸…ç†èµ„æºï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
            self._cleanup_resources(all_out_pils)

            # æ¸…ç†ä¸´æ—¶Keyå’Œä¸Šä¸‹æ–‡
            config_manager.clear_temp_keys()

            # æ¸…é™¤ApiKeyManagerçš„ä¸Šä¸‹æ–‡
            api_key_manager.clear_key_context()

            return (out_tensor, final_status, final_key_status)
            
        except Exception as e:
            error_msg = f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {e}"
            if log_id:
                task_logger.log_error(log_id, error_msg, "execution")
                task_logger.update_task_status(log_id, TaskStatus.FAILED, error_msg)
            
            # åœ¨å¼‚å¸¸æƒ…å†µä¸‹ä¹Ÿè¦æ¸…ç†èµ„æº
            self._cleanup_resources(all_input_pils)

            # æ¸…ç†ä¸´æ—¶Keyå’Œä¸Šä¸‹æ–‡
            config_manager.clear_temp_keys()

            # æ¸…é™¤ApiKeyManagerçš„ä¸Šä¸‹æ–‡
            api_key_manager.clear_key_context()

            return (pils_to_tensor(all_input_pils), error_msg, "æ‰§è¡Œå¼‚å¸¸")
    
    def _process_batch_file(self, managers: Tuple, log_id: str,
                           pil_refs: List[Image.Image], file_path: str,
                           site_url: str, site_name: str, model: str,
                           max_concurrent: int, max_retries: int) -> Tuple[List[Image.Image], List[str]]:
        """å¤„ç†æ‰¹é‡æ–‡ä»¶"""
        config_manager, api_key_manager, task_logger = managers
        
        # æ”¹è¿›çš„è·¯å¾„å¤„ç†
        clean_path = file_path.strip()
        if (clean_path.startswith('"') and clean_path.endswith('"')) or \
           (clean_path.startswith("'") and clean_path.endswith("'")):
            clean_path = clean_path[1:-1]
        
        import re
        clean_path = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', clean_path)
        clean_path = os.path.normpath(clean_path)
        
        if not os.path.exists(clean_path):
            return [], [f"é”™è¯¯ï¼šæ–‡ä»¶è·¯å¾„ä¸å­˜åœ¨: {clean_path}"]
        
        if not HAS_PANDAS:
            return [], ["é”™è¯¯ï¼šæ‰¹é‡æ¨¡å¼éœ€è¦ pandas"]
        
        try:
            if clean_path.lower().endswith(".csv"):
                try:
                    df = pd.read_csv(clean_path, encoding='utf-8')
                except UnicodeDecodeError:
                    try:
                        df = pd.read_csv(clean_path, encoding='gbk')
                    except UnicodeDecodeError:
                        df = pd.read_csv(clean_path, encoding='latin1')
            else:
                df = pd.read_excel(clean_path, sheet_name="Sheet1")
        except Exception as e:
            return [], [f"è¯»å–æ–‡ä»¶å¤±è´¥ï¼š{e}"]
        
        if "prompt" not in df.columns:
            return [], ["é”™è¯¯ï¼šæ–‡ä»¶ä¸­æœªæ‰¾åˆ° 'prompt' åˆ—"]
        
        prompts = [row.get("prompt", "") for _, row in df.iterrows()]
        return self._process_batch_concurrent(
            managers, log_id, prompts, pil_refs,
            site_url, site_name, model, max_concurrent, max_retries
        )


# æ³¨å†Œåˆ° ComfyUI
# 2. ä¿®æ”¹èŠ‚ç‚¹ç±»æ˜ å°„ï¼Œä½¿ç”¨æ–°çš„ç±»åä½œä¸ºé”®å’Œå€¼
NODE_CLASS_MAPPINGS = {
    "GoogleNanoNode": GoogleNanoNode,
}
# 3. ä¿®æ”¹èŠ‚ç‚¹æ˜¾ç¤ºåç§°æ˜ å°„ï¼Œä½¿ç”¨æ–°çš„ç±»åä½œä¸ºé”®
NODE_DISPLAY_NAME_MAPPINGS = {
    "GoogleNanoNode": "google nano",
}
